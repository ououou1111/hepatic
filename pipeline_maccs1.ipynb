{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02741d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import *\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, PandasTools\n",
    "import graphviz\n",
    "import joblib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from math import *\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61ad767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('TLR4_activity_SMILES.csv',usecols=[1],names=None)\n",
    "\n",
    "df_li=df.values.tolist()\n",
    "result=[]\n",
    "for s_li in df_li:\n",
    "    result.append(s_li[0])\n",
    "\n",
    "mol=[Chem.MolFromSmiles(i) for i in result]\n",
    "df['mol']=mol\n",
    "df['mol'] = df['mol'].map(lambda x: False if x == None else True)\n",
    "del_index = df[df['mol'] == False].index\n",
    "df2 = df.drop(del_index)\n",
    "mols = [Chem.MolFromSmiles(smile) for smile in df2['SMILES']]\n",
    "maccskeys = []\n",
    "for m in mols:\n",
    "    maccskey = [x for x in AllChem.GetMACCSKeysFingerprint(m)]\n",
    "    maccskeys.append(maccskey)\n",
    "maccskeys = np.array(maccskeys)\n",
    "\n",
    "df=pd.read_csv('TLR4_activity_SMILES.csv',names=None)\n",
    "\n",
    "merge=pd.concat([df2,df],axis=1,join='inner')\n",
    "merge.activity=merge.activity.astype(str).map({'Inactive':0, 'Active':1})\n",
    "\n",
    "y=merge.activity\n",
    "x=pd.DataFrame(maccskeys)\n",
    "m=pd.DataFrame(x)\n",
    "X=maccskeys\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(x)\n",
    "#joblib.dump(X,'xydataset/geneid_x_s.pkl')\n",
    "#joblib.dump(y,'xydataset/geneid_y_s.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccc91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE算法及其python实现\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class Smote:\n",
    "    def __init__(self, samples, N=100, k=5):\n",
    "        self.n_samples, self.n_attrs = samples.shape\n",
    "        self.N = N\n",
    "        self.k = k\n",
    "        self.samples = samples\n",
    "        self.newindex = 0\n",
    "        self.synthetic = np.zeros((self.n_samples * int(N / 100), self.n_attrs))\n",
    "\n",
    "    def over_sampling(self):\n",
    "        neighbors = NearestNeighbors(n_neighbors=self.k).fit(self.samples)\n",
    "\n",
    "        for i in range(len(self.samples)):\n",
    "            nnarray = neighbors.kneighbors(self.samples[i].reshape(1,-1), return_distance=False)[0]\n",
    "            self._populate(int(self.N/100), i, nnarray)\n",
    "\n",
    "        return self.synthetic\n",
    "\n",
    "    def _populate(self, N, i, nnarray):\n",
    "        for j in range(N):\n",
    "            nn = random.randint(0, len(nnarray)-1)\n",
    "            dif = self.samples[nnarray[nn]] - self.samples[i]\n",
    "            gap = random.random()\n",
    "            self.synthetic[self.newindex] = self.samples[i] + gap * dif\n",
    "            self.newindex += 1\n",
    "            \n",
    "X=maccskeys\n",
    "s=Smote(X,N=100)\n",
    "x=s.over_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b133467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993851911253675\n",
      "0.7459518990103772\n",
      "0.8802438568964215\n",
      "0.7261117911056711\n",
      "0.7786269420634401\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    " \n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    " \n",
    "    # 训练模型\n",
    "    knn.fit(X_train, y_train)\n",
    " \n",
    " # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = knn.predict(X_validation)\n",
    "    y_validation_pred_prob = knn.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/knn/scorelist/acc/geneid_knn_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/knn/scorelist/f1/geneid_knn_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/knn/scorelist/auc/geneid_knn_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/knn/scorelist/recall/geneid_knn_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/knn/scorelist/precision/geneid_knn_precision.pkl')\n",
    "#joblib.dump(knn,'model_pkl/knn/geneid_s_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cacfa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8293504410585406\n",
      "0.7827217152843057\n",
      "0.8892568339689385\n",
      "0.7580753015001471\n",
      "0.8206151351901532\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    " \n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    " \n",
    "    # 训练模型\n",
    "    svm.fit(X_train, y_train)\n",
    " \n",
    " # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = svm.predict(X_validation)\n",
    "    y_validation_pred_prob = svm.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/svm/scorelist/acc/geneid_svm_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/svm/scorelist/f1/geneid_svm_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/svm/scorelist/auc/geneid_svm_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/svm/scorelist/recall/geneid_svm_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/svm/scorelist/precision/geneid_svm_precision.pkl')\n",
    "#joblib.dump(svm,'model_pkl/svm/geneid_s_svm.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67dc3ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8201817695803261\n",
      "0.7702578607014174\n",
      "0.894582536256068\n",
      "0.7495195195195195\n",
      "0.7998920369037492\n"
     ]
    }
   ],
   "source": [
    "#rfc\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    "\n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "\n",
    "    # 定义参数搜索空间，并进行网格搜索\n",
    "    param_grid = {'n_estimators': [10, 50, 100], \n",
    "                  'max_depth': [3, 5, 7]}\n",
    "    rfc = RandomForestClassifier()\n",
    "    gs = GridSearchCV(rfc, param_grid, cv=5)\n",
    "    gs.fit(X_train, y_train)  # 搜索最佳超参数组合（很耗时！）\n",
    "    # 携带最佳超参数组合的RFC对象\n",
    "    best_rfc = gs.best_estimator_\n",
    "\n",
    "    # 训练模型，并在验证集上评估性能\n",
    "    best_rfc.fit(X_train, y_train)\n",
    "    y_validation_pred = best_rfc.predict(X_validation)\n",
    "    y_validation_pred_prob = best_rfc.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    "\n",
    "\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/rfc/scorelist/acc/geneid_rfc_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/rfc/scorelist/f1/geneid_rfc_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/rfc/scorelist/auc/geneid_rfc_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/rfc/scorelist/recall/geneid_rfc_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/rfc/scorelist/precision/geneid_rfc_precision.pkl')\n",
    "#joblib.dump(best_rfc,'model_pkl/rfc/geneid_s_rfc.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d073f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993584603047313\n",
      "0.7324964593130379\n",
      "0.8300852554993975\n",
      "0.7428545963840081\n",
      "0.7288523195707649\n"
     ]
    }
   ],
   "source": [
    "#dt\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    "\n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "\n",
    "    # 定义参数搜索空间，并进行网格搜索\n",
    "    param_grid = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    dt = DecisionTreeClassifier()\n",
    "    gs = GridSearchCV(dt,param_grid,cv=5)\n",
    "    gs.fit(X_train, y_train)  # 搜索最佳超参数组合（很耗时！）\n",
    "    # 携带最佳超参数组合的RFC对象\n",
    "    best_dt = gs.best_estimator_\n",
    "\n",
    "    # 训练模型，并在验证集上评估性能\n",
    "    best_dt.fit(X_train, y_train)\n",
    "    y_validation_pred = best_dt.predict(X_validation)\n",
    "    y_validation_pred_prob = best_dt.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    "\n",
    "\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/dt/scorelist/acc/geneid_dt_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/dt/scorelist/f1/geneid_dt_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/dt/scorelist/auc/geneid_dt_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/dt/scorelist/recall/geneid_dt_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/dt/scorelist/precision/geneid_dt_precision.pkl')\n",
    "#joblib.dump(best_dt,'model_pkl/dt/geneid_s_dt.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf582c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6910184442662389\n",
      "0.6255703144218765\n",
      "0.8209046640628144\n",
      "0.5798886858325983\n",
      "0.6860923902375188\n"
     ]
    }
   ],
   "source": [
    "#mnb\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    " \n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    " \n",
    "    # 训练模型\n",
    "    mnb.fit(X_train, y_train)\n",
    " \n",
    " # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = mnb.predict(X_validation)\n",
    "    y_validation_pred_prob = mnb.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/nb/scorelist/acc/ABL1_nb_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/nb/scorelist/f1/ABL1_nb_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/nb/scorelist/auc/ABL1_nb_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/nb/scorelist/recall/ABL1_nb_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/nb/scorelist/precision/ABL1_nb_precision.pkl')\n",
    "#joblib.dump(svm,'model_pkl/nb/ABL1_s_nb.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a63c5cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7787757284148624\n",
      "0.7116674629718108\n",
      "0.8833101741766403\n",
      "0.6993403813138158\n",
      "0.7254494827222695\n"
     ]
    }
   ],
   "source": [
    "#adaboost\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    "\n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    x_train, x_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "\n",
    "    # 定义参数搜索空间，并进行网格搜索\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 200, 500], \n",
    "        'learning_rate': [0.01, 0.1, 1, 10]\n",
    "    }\n",
    "    adaboost = AdaBoostClassifier(base_estimator=best_dt)\n",
    "    gs = GridSearchCV(adaboost,param_grid,cv=5)\n",
    "    gs.fit(x_train,y_train)  # 搜索最佳超参数组合（很耗时！）\n",
    "    # 携带最佳超参数组合的AdaBoost对象\n",
    "    best_adaboost = gs.best_estimator_\n",
    "\n",
    "    # 使用最佳超参数组合的分类器进行拟合训练\n",
    "    best_adaboost.fit(x_train, y_train)\n",
    "\n",
    "    # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = best_adaboost.predict(x_validation)\n",
    "    y_validation_pred_prob = best_adaboost.predict_proba(x_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/adaboost/scorelist/acc/ABL1_adaboost_lda_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/adaboost/scorelist/f1/ABL1_adaboost_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/adaboost/scorelist/auc/ABL1_adaboost_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/adaboost/scorelist/recall/ABL1_adaboost_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/adaboost/scorelist/precision/ABL1_adaboost_precision.pkl')\n",
    "#joblib.dump(svm,'model_pkl/adaboost/ABL1_s_adaboost.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac15d8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7648489708634055\n",
      "0.6959248573187573\n",
      "0.8185722231866889\n",
      "0.6869154310484786\n",
      "0.7123037943393894\n"
     ]
    }
   ],
   "source": [
    "# 定义LDA模型\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    " \n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    " \n",
    "    # 训练模型\n",
    "    lda.fit(X_train, y_train)\n",
    " \n",
    " # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = lda.predict(X_validation)\n",
    "    y_validation_pred_prob = lda.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/LDA/scorelist/acc/ABL1_lda_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/LDA/scorelist/f1/ABL1_lda_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/LDA/scorelist/auc/ABL1_lda_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/LDA/scorelist/recall/ABL1_lda_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/LDA/scorelist/precision/ABL1_lda_precision.pkl')\n",
    "#joblib.dump(svm,'model_pkl/LDA/ABL1_s_lda.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fdecad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qinyf/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/qinyf/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/qinyf/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8133386794974605\n",
      "0.7545797553994276\n",
      "0.8851987757842149\n",
      "0.7568445052439581\n",
      "0.7623208794084931\n"
     ]
    }
   ],
   "source": [
    "#lr\n",
    "\n",
    "# 定义逻辑回归模型\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    " \n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    " \n",
    "    # 训练模型\n",
    "    lr.fit(X_train, y_train)\n",
    " \n",
    " # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = lr.predict(X_validation)\n",
    "    y_validation_pred_prob = lr.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/lr/scorelist/acc/ABL1_lr_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/lr/scorelist/f1/ABL1_lr_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/lr/scorelist/auc/ABL1_lr_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/lr/scorelist/recall/ABL1_lr_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/lr/scorelist/precision/ABL1_lr_precision.pkl')\n",
    "#joblib.dump(svm,'model_pkl/lr/ABL1_s_lr.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede6c1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8017375033413525\n",
      "0.7469041454326264\n",
      "0.8929774660054047\n",
      "0.7262566844919787\n",
      "0.7785088006281489\n"
     ]
    }
   ],
   "source": [
    "#ensemble\n",
    "\n",
    "# 创建各个基分类器\n",
    "nn_clf = MLPClassifier()\n",
    "\n",
    "# 创建AdaBoost分类器\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn', knn), \n",
    "        ('svm', svm), \n",
    "        ('rf', best_rfc), \n",
    "        ('dt', best_dt), \n",
    "        ('nb', mnb), \n",
    "        ('adaBoost', best_adaboost), \n",
    "        ('lda', lda), \n",
    "        ('lr', lr), \n",
    "        ('mlp', nn_clf)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# 定义五折交叉验证迭代器\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    " \n",
    "# 定义一个空列表，用于保存每个模型在验证集上的准确率\n",
    "accuracy_scores, auc_scores, f1_scores, recall_scores, precision_scores = [], [], [], [], []\n",
    " \n",
    "# 开始五折交叉验证\n",
    "for train_index, validation_index in kfold.split(X):\n",
    "    # 将数据集分成训练集和验证集\n",
    "    X_train, X_validation = X[train_index], X[validation_index]\n",
    "    y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    " \n",
    "    # 训练模型\n",
    "    voting_clf.fit(X_train, y_train)\n",
    " \n",
    " # 验证并评估模型在验证集上的性能\n",
    "    y_validation_pred = voting_clf.predict(X_validation)\n",
    "    y_validation_pred_prob = voting_clf.predict_proba(X_validation)[:, 1] # 取正例的概率值，用于计算AUC\n",
    "    accuracy_scores.append(accuracy_score(y_validation, y_validation_pred))\n",
    "    auc_scores.append(roc_auc_score(y_validation, y_validation_pred_prob))\n",
    "    f1_scores.append(f1_score(y_validation, y_validation_pred))\n",
    "    recall_scores.append(recall_score(y_validation, y_validation_pred))\n",
    "    precision_scores.append(precision_score(y_validation, y_validation_pred))\n",
    " \n",
    "# 输出每个模型在不同指标下的性能表现\n",
    "print(np.mean(accuracy_scores))\n",
    "print(np.mean(f1_scores))\n",
    "print(np.mean(auc_scores))\n",
    "print(np.mean(precision_scores))\n",
    "print(np.mean(recall_scores))\n",
    "#joblib.dump(accuracy_scores,'model_pkl/ensemble_scorelist/acc/ABL1_acc.pkl')\n",
    "#joblib.dump(f1_scores,'model_pkl/ensemble_scorelist/f1/ABL1_f1.pkl')\n",
    "#joblib.dump(auc_scores,'model_pkl/ensemble_scorelist/auc/ABL1_auc.pkl')\n",
    "#joblib.dump(recall_scores,'model_pkl/ensemble_scorelist/recall/ABL1_recall.pkl')\n",
    "#joblib.dump(precision_score,'model_pkl/ensemble_scorelist/precision/ABL1_precision.pkl')\n",
    "#joblib.dump(voting_clf,'model_pkl/ABL1_s_ensemble.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5312eec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('OC1=CC=C(CC2=CC=C(O)C=C2)C=C1')#BPF\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01ba2b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('C1=CC=C2C(=C1)C3=CC=CC=C3C2(C4=CC5=C(C=C4)C(=O)OC5=O)C6=CC7=C(C=C6)C(=O)OC7=O')#BPAF\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea5f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('OC1=CC=C(C=C1)S(=O)(=O)C1=CC=C(O)C=C1')#BPS\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e57c32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C1=CC=CC=C1)(C1=CC=C(O)C=C1)C1=CC=C(O)C=C1')#BPAP\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d26f5227",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('Cl.CC1=NN(C(=N)N=C(N)N)C(C)(C)C1')#BPC\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f56b1abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(CCC(O)=O)(C1=CC=C(O)C=C1)C1=CC=C(O)C=C1')#BPACID\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8d1d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('OC1=CC=C(C=C1)C1(CCCCC1)C1=CC=C(O)C=C1')#BPZ\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d10be1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C)(C1=CC(=C(O)C=C1)C1=CC=CC=C1)C1=CC(=C(O)C=C1)C1=CC=CC=C1')#BPOPPA\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6feb38c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CCC(C)(C1=CC=C(O)C=C1)C1=CC=C(O)C=C1')#BPB\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88d73cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('OC1=CC=C(C=C1)C1(C2=C(C=CC=C2)C2=C1C=CC=C2)C1=CC=C(O)C=C1')#BPFL\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f8d6b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C1=CC=C(OC#N)C=C1)C1=CC=C(OC#N)C=C1')#1,-is(4-yanatophenyl)thane\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c834343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('OC(=O)COC1=CC=C(Cl)C=C1')#4-CP\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f60bd11f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(=C)C(=O)OCC(O)COC1=CC=C(C=C1)C(C)(C)C1=CC=C(OCC(O)COC(=O)C(C)=C)C=C1')#BPAGM\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d8355d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C)(C1=CC=C(OC#N)C=C1)C1=CC=C(OC#N)C=C1')#1,3-Bis(4-cyanophenyl)propane\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88d4b120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('O=C(N1CCCCC1)C1=CC2=C(OCCO2)C=C1')#BDP\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6940eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C)(C1=CC=C(OC2=CC3=C(C=C2)C(=O)OC3=O)C=C1)C1=CC=C(OC2=CC3=C(C=C2)C(=O)OC3=O)C=C1')#BPADA\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e51f9103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(=O)OC1=CC=C(C=C1)C(C)(C)C1=CC=C(OC(C)=O)C=C1')#BPAD\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45e22c1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C)(C1=CC=C(OCC=C)C=C1)C1=CC=C(OCC=C)C=C1')#BPE\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b33de7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C)(C1=CC=C(OC#N)C=C1)C1=CC=C(OC#N)C=C1')#BPACE\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c8cd2a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[0]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "mol=Chem.MolFromSmiles('CC(C)(C1=CC=C(OCCO)C=C1)C1=CC=C(OCCO)C=C1')#Diano 22\n",
    "maccskey=AllChem.GetMACCSKeysFingerprint(mol)\n",
    "maccs= np.array(maccskey).reshape(1,-1)\n",
    "print(knn.predict(maccs))\n",
    "print(svm.predict(maccs))\n",
    "print(best_rfc.predict(maccs))\n",
    "print(best_dt.predict(maccs))\n",
    "print(mnb.predict(maccs))\n",
    "print(best_adaboost.predict(maccs))\n",
    "print(lda.predict(maccs))\n",
    "print(lr.predict(maccs))\n",
    "print(voting_clf.predict(maccs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e53a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984d250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a391d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09545bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be52416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826a752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59568142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d219c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6255b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4ebad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e449411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a749733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1bb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663577d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee34c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5b803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d4f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff69db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
